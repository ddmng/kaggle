{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras ImageDataGenerator\n",
    "Here I'm using Keras [`ImageDataGenerator`](https://keras.io/preprocessing/image/) to read files from the `train` directory and feed a very simple CNN. I'm still not searching for accuracy here, just trying to simplify the pipeline. ImageDataGenerator has the ability to generate a flow of images to the CNN, applying:\n",
    "* resampling to a smaller size\n",
    "* changing to grayscale if needed\n",
    "* train/validation split (still not done here)\n",
    "* data augmentation\n",
    "\n",
    "TODO:\n",
    "* resample to a different size\n",
    "* change the CNN to a more effective one\n",
    "* ~~add the validation_generator and pass it to the model's `fit_generator` method~~\n",
    "* analyze source data\n",
    "* train on whole dataset\n",
    "* data augmentation\n",
    "* implement Mean Average Precision @ 5 for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, ZeroPadding2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Input, Model\n",
    "from scipy.misc import imresize\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test', 'sample_submission.csv', 'train']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator requires `filename` and `class` respectively for the column with all the file names and for the other with the classes. Here I change the columns names but I could have used:\n",
    "\n",
    "    x_col: string, column in the dataframe that contains\n",
    "           the filenames of the target images.\n",
    "    y_col: string or list of strings,columns in\n",
    "           the dataframe that will be the target data.\n",
    "in `flow_from_dataframe` method to override the default Keras behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20621</th>\n",
       "      <td>cfb8c68dc.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152</th>\n",
       "      <td>66bf04895.jpg</td>\n",
       "      <td>w_b27b6c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21324</th>\n",
       "      <td>d6a92a7f9.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16229</th>\n",
       "      <td>a37e5cc98.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>2a215f11e.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename      class\n",
       "20621  cfb8c68dc.jpg  new_whale\n",
       "10152  66bf04895.jpg  w_b27b6c6\n",
       "21324  d6a92a7f9.jpg  new_whale\n",
       "16229  a37e5cc98.jpg  new_whale\n",
       "4097   2a215f11e.jpg  new_whale"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../input/train.csv\")\n",
    "dataset.columns = ['filename', 'class'] # renaming to match ImageDataGenerator expectations\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25361, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use only a subset of all the 25k picture in order to be faster. Slicing the dataframe is enough.\n",
    "\n",
    "* `batch_size` controls how many samples the generator sends to the network each step\n",
    "* `subset` is used to slice the source dataset and work on a smaller one when making experiments\n",
    "* `target_size` is the image shape to use in the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20289 images belonging to 5005 classes.\n",
      "Found 5072 images belonging to 5005 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5072"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "subset = 500\n",
    "target_size = (224, 224, 1)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=.2)\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "        directory='../input/train',\n",
    "        dataframe=dataset,\n",
    "        subset='training',\n",
    "        target_size=target_size[0:2],\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        interpolation='nearest')\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "        directory='../input/train',\n",
    "        dataframe=dataset,\n",
    "        subset='validation',\n",
    "        target_size=target_size[0:2],\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        interpolation='nearest')\n",
    "\n",
    "len(train_generator.classes)\n",
    "len(val_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN. Notes:\n",
    "* optimizer set to Adam with default learning rate of .02 and a learning rate decay at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 108, 108, 64)      5248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 54, 54, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 6, 6, 128)         8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 3, 3, 384)         49536     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 1, 1, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 1, 1, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 1, 1, 512)         197120    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5005)              2567565   \n",
      "=================================================================\n",
      "Total params: 3,167,117\n",
      "Trainable params: 3,165,709\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape = target_size)\n",
    "\n",
    "x1 = Conv2D(64, (9, 9), strides=2, activation='relu')(inp)\n",
    "x1 = MaxPool2D((2,2), strides=(2,2))(x1)\n",
    "\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Conv2D(64, (3, 3), strides=2, activation='relu')(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = Conv2D(64, (3, 3), strides=2, activation='relu')(x1)\n",
    "\n",
    "x1 = MaxPool2D((2,2))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "x1 = Conv2D(128, (1, 1), activation='relu')(x1)\n",
    "x1 = MaxPool2D((2,2), strides=(2,2))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "x1 = Conv2D(384, (1, 1), activation='relu')(x1)\n",
    "x1 = MaxPool2D((2,2), strides=(2,2))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "\n",
    "x1 = Conv2D(512, (1, 1), activation='relu')(x1)\n",
    "x1 = Dropout(.25)(x1)\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "x1 = Dense(512, activation='relu')(x1)\n",
    "\n",
    "x1 = Dense(5005, activation='softmax')(x1)\n",
    "\n",
    "model = Model(inputs=inp, outputs=x1)\n",
    "\n",
    "opt = Adam(lr=0.02, decay=0.00)\n",
    "model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.build(input_shape = target_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  11/2028 [..............................] - ETA: 4:07:11 - loss: 10.0393 - acc: 0.3341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\", line 401, in get_index\n",
      "    return _SHARED_SEQUENCES[uid][i]\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/site-packages/keras_preprocessing/image.py\", line 1441, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/site-packages/keras_preprocessing/image.py\", line 2151, in _get_batches_of_transformed_samples\n",
      "    img = load_img(os.path.join(self.directory, fname),\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/posixpath.py\", line 87, in join\n",
      "    if b.startswith(sep):\n",
      "  File \"/home/daniele/miniconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bed15328b746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                   \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5072\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                   validation_data=val_generator)\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Creates a graph.\n",
    "with tf.device('/device:GPU:0'):\n",
    "    history = model.fit_generator(train_generator, \n",
    "                                  epochs=epochs, \n",
    "                                  steps_per_epoch=20289//epochs,\n",
    "                                  use_multiprocessing=True,\n",
    "                                  validation_steps=5072//epochs,\n",
    "                                  validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO BE CONTINUED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
