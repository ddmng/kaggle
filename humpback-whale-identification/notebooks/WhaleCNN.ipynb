{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras ImageDataGenerator\n",
    "Here I'm using Keras [`ImageDataGenerator`](https://keras.io/preprocessing/image/) to read files from the `train` directory and feed a very simple CNN. I'm still not searching for accuracy here, just trying to simplify the pipeline. ImageDataGenerator has the ability to generate a flow of images to the CNN, applying:\n",
    "* resampling to a smaller size\n",
    "* changing to grayscale if needed\n",
    "* train/validation split (still not done here)\n",
    "* data augmentation\n",
    "\n",
    "TODO:\n",
    "* resample to a different size\n",
    "* change the CNN to a more effective one\n",
    "* add the validation_generator and pass it to the model's `fit_generator` method\n",
    "* analyze source data\n",
    "* train on whole dataset\n",
    "* data augmentation\n",
    "* implement Mean Average Precision @ 5 for submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import imshow\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, ZeroPadding2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from scipy.misc import imresize\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test', 'sample_submission.csv', 'train']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator requires `filename` and `class` respectively for the column with all the file names and for the other with the classes. Here I change the columns names but I could have used:\n",
    "\n",
    "    x_col: string, column in the dataframe that contains\n",
    "           the filenames of the target images.\n",
    "    y_col: string or list of strings,columns in\n",
    "           the dataframe that will be the target data.\n",
    "in `flow_from_dataframe` method to override the default Keras behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20621</th>\n",
       "      <td>cfb8c68dc.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152</th>\n",
       "      <td>66bf04895.jpg</td>\n",
       "      <td>w_b27b6c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21324</th>\n",
       "      <td>d6a92a7f9.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16229</th>\n",
       "      <td>a37e5cc98.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>2a215f11e.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename      class\n",
       "20621  cfb8c68dc.jpg  new_whale\n",
       "10152  66bf04895.jpg  w_b27b6c6\n",
       "21324  d6a92a7f9.jpg  new_whale\n",
       "16229  a37e5cc98.jpg  new_whale\n",
       "4097   2a215f11e.jpg  new_whale"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../input/train.csv\")\n",
    "dataset.columns = ['filename', 'class'] # renaming to match ImageDataGenerator expectations\n",
    "dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25361, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use only a subset of all the 25k picture in order to be faster. Slicing the dataframe is enough.\n",
    "\n",
    "* `batch_size` controls how many samples the generator sends to the network each step\n",
    "* `subset` is used to slice the source dataset and work on a smaller one when making experiments\n",
    "* `target_size` is the image shape to use in the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 284 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 128\n",
    "subset = 500\n",
    "target_size = (100, 100, 3)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    validation_split=.2,\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=dataset.iloc[:subset],\n",
    "        directory='../input/train',\n",
    "        target_size=target_size[0:2],\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        interpolation='nearest')\n",
    "\n",
    "num_classes = len(np.unique(train_generator.classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN. Notes:\n",
    "* `target_size` is passed to the first layer\n",
    "* optimizer set to Adam with default learning rate of .02 and a learning rate decay at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 100, 100, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 94, 94, 32)        4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 70688)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               7068900   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 284)               28684     \n",
      "=================================================================\n",
      "Total params: 7,102,332\n",
      "Trainable params: 7,102,326\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape = target_size ))\n",
    "model.add(Conv2D(filters=32, \n",
    "                 kernel_size=(7,7), \n",
    "                 activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "opt = Adam(lr=0.02, decay=0.005)\n",
    "model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "111/166 [===================>..........] - ETA: 1:35 - loss: 9.7533 - categorical_accuracy: 0.3891"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=epochs, steps_per_epoch=subset//epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.title('Model categorical_accuracy')\n",
    "plt.ylabel('categorical_accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO BE CONTINUED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
